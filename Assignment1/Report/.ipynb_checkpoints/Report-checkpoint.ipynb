{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Multimedia Retrieval and Content-Based Search</h1>\n",
    "<h3>Assignment 1 - Report</h3><p>\n",
    "<i><b>Oliver Schweiger, 01220194</b></i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 1</h3>\n",
    "\n",
    "<u>What are the shortcomings of the raw term frequency calculation and how do they affect a retrieval system?</u></li><br>\n",
    "Answer: Though raw frequency of a term is serviceable as an indicator of document relevance, there are just\n",
    "too many things not considered by it. Primarily, you want to have at least some weighting that\n",
    "prevents the tf-value from growing too large and thus distorting the results when comparing large\n",
    "documents (common words like ‘a’ or ‘the’): the logarithm used in log frequency weighting does\n",
    "exactly that. Also, you might want to have a weight related to term relevance - terms that appear\n",
    "often should not be weighted as much as rare terms (independent from raw tf). The idf-value does\n",
    "just that. Other things like term ordering are also lost when using just raw tf.\n",
    "      \n",
    "<u>Evaluate the following statements:<br></u>\n",
    "<p><u>Using a tf-idf weighting scheme, the weight of a term t in a document d is....&nbsp;</u><br>\n",
    "<br><u>...lowest when t occurs many times in many documents&nbsp;</u><br>\n",
    "The term occurring in many documents is an indicator of it being less relevant, but it still occurs many times per document and it doesn’t occur in every document so its idf will be low to moderate.\n",
    "    \n",
    "<u>...highest when t occurs very often in all documents</u><br>\n",
    "False, if a term occurs in all documents, as can be show in the operation below, its weight will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "N = 5; df = 5;\n",
    "math.log10( N / df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><u>...highest when t occurs many times in few documents</u><br>\n",
    "True, a high tf and high inverse df (meaning a low df) is an indicator of high relevance.\n",
    "\n",
    "<u>...growing when the occurrence&nbsp;of t increases proportionally with the amount of documents t occurs in</u><br>\n",
    "(assuming the collection size stays the same): Not generally. It depends on the Collection Size. For low df values (with respect to the collection size) there is a growth to be observed, but after a certain value the idf part of the equation gets too close to zero for the tf-part to counteract it, resulting in a decrease. This behavior is shown in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf: 3.282\n",
      "tf-idf: 3.560\n",
      "tf-idf: 3.638\n",
      "tf-idf: 3.655\n",
      "tf-idf: 3.648\n",
      "tf-idf: 3.628\n",
      "tf-idf: 3.601\n",
      "tf-idf: 3.570\n",
      "tf-idf: 3.538\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "N = 1000 #collection size\n",
    "i = 1\n",
    "while i<10:\n",
    "    tf = i * 2;\n",
    "    df = i * 3;\n",
    "    tf_idf = (1 + math.log10(tf)) * math.log10( N / df)\n",
    "    print('tf-idf: %.3f' %tf_idf)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Why is a document-level statistic for term weighting to be preferred over a collection-wide statistic?</u><br>\n",
    "Using the df over the cf (collection frequency) for the calculation of the tf-idf is better because a low df\n",
    "value is a better indicator for term rarity than the cf. A term might appear often in (domain specific)\n",
    "document but not in general. This results in low df’s but still way higher cf’s, making the df’s inverse\n",
    "higher, thus assigning the more rare term a higher relevance. This way, we can also decrease the\n",
    "influence of possible fake sites that try to manipulate the tf-idfs. The df value makes their (fake)\n",
    "contributions matter much less than the cf would. Of course, for queries it also makes more sense to\n",
    "use the doc-related tf as a basis since we want our queries to be answered document based and not\n",
    "collection based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 3</h3>\n",
    "\n",
    "<u>Think about the relationship between information need and query -- what is a query?</u><br>\n",
    "    \n",
    "A query is a textual abstraction that describes my information needs and which then gets processed\n",
    "within the IR System to deliver a result that best fulfills this need. Neither query nor query-results will\n",
    "be 100% precise, but it’s important to get close, by having the user formulate a precise query and the\n",
    "IR system offer high precision/recall.\n",
    "\n",
    "<u>Critically think about the differences between the Boolean retrieval model and a ranked retrieval\n",
    "model building upon e.g. the vector space model.</u><br>\n",
    "\n",
    "For some Use Cases/Systems a boolean model might still be a good solution, but in the context of web\n",
    "search engines, the ranked model has prevailed since there is often not “the” right answer to a query\n",
    "but multiple ones that might be interesting to the user to different degrees. For other systems (for\n",
    "example law) this might not be the case.\n",
    "\n",
    "<u>Explain why a query for the term \"a\" produces the given result</u><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 1.0), (6, 1.0), (1, 0.9449), (4, 0.5), (2, 0.2236), (3, 0.0)] \n",
      "\n",
      "[(2, 0.6708), (4, 0.5), (1, 0.189), (3, 0.1562), (5, 0.0), (6, 0.0)] \n",
      "\n",
      "[(2, 0.6708), (4, 0.5), (3, 0.3123), (1, 0.189), (5, 0.0), (6, 0.0)] \n",
      "\n",
      "[(2, 0.9487), (4, 0.7071), (3, 0.3313), (1, 0.2673), (5, 0.0), (6, 0.0)] \n",
      "\n",
      "[(4, 1.0), (2, 0.8944), (1, 0.7559), (3, 0.7028), (5, 0.5), (6, 0.5)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ../Task3/Implementation.ipynb\n",
    "\n",
    "table_tfidf = calculate_tfidf('../collection2.txt')\n",
    "print(perform_query(table_tfidf, 'a'), '\\n')\n",
    "\n",
    "print(perform_query(table_tfidf, 'b'), '\\n')\n",
    "\n",
    "print(perform_query(table_tfidf, 'c'), '\\n')\n",
    "\n",
    "print(perform_query(table_tfidf, 'b c'), '\\n')\n",
    "\n",
    "print(perform_query(table_tfidf, 'a b c d'), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "Doc 5 and 6 rank highest since it only consists of a’s. Also it doesn’t matter how many a’s are in the\n",
    "doc, since its vector representation is normed, making its length irrelevant -> (1, 0, 0) and (3, 0, 0) is\n",
    "the same, when normed. For the other ones: the more a’s in proportion to the rest of the document,\n",
    "the higher the similarity.\n",
    "\n",
    "<u>Why does Doc1 receive a higher rank than Doc3 when the term \"b\" is queried: </u><br>\n",
    "Because in Doc 1, there are more b’s with respect to other entries (1/8 is ‘b’), where as 1/9 is ‘b’ for Doc 3.\n",
    "    \n",
    "<u>Why is the rank of Doc3 lower than the rank of Doc2 although Doc2 contains more \"c\" terms when a query for the term \"c\" is issued: </u><br>\n",
    "Doc2 contains more c’s and is also shorter, which makes it higher ranked.\n",
    "    \n",
    "<u>Why does Doc2 receive a higher rank than Doc4 when the query contains the terms \"b c\": </u><br>\n",
    "Half of the Doc4 is made out of “b c”, but 6/8 of Doc2 is made out of “b c”, making it the better match.\n",
    "\n",
    "<u>Consider the query \"a b c d\" -- which document receives the highest rank and why: </u><br>\n",
    "Doc4, since it only consists of these terms. It ranks higher than 1, 2 and 3 because the proportion of the terms within the\n",
    "query fits better than for the other docs.\n",
    "\n",
    "<u>Critically think about what do these numbers represent and how do they express similarity?</u><br>\n",
    "The higher the number, the higher the similarity. As described above, tf offers a decent but not\n",
    "perfect measure for similarity, since it doesn’t account for term rarity. It also doesn’t check for\n",
    "ordering. The cosine similarity also has the property of just comparing the vectors angles. This is the\n",
    "reason why two docs “a” and “a a” are considered identical - their vectors point in the exact same\n",
    "direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 4:</h3>\n",
    "    \n",
    "<u>Outline how the result of a PageRank calculation can be integrated into the calculation process of a\n",
    "retrieval (similarity) score</u>\n",
    "\n",
    "Easiest way to do it would be to just multiply a page’s rank onto the similarity score, making popular\n",
    "pages rise in query-similarity (more likely to be seen) and less popular ones rank lower (even though\n",
    "they might have had a higher base similarity in terms of tf-idf)\n",
    "\n",
    "<u>Think about the nature of the PageRank and ascertain whether it is a query-dependent or query-independent measure?</u>\n",
    "\n",
    "Page Ranks are calculated independent from a single query (on a search engines web server for\n",
    "example) a-priori. So in principle, they are independent from a specific query. Page Rank, however, is\n",
    "calculated based on web page’s visit rates, meaning that there could very well a high-level relationship\n",
    "between queries and Page Rank, because users tend to visit pages that conform to their queries, in\n",
    "turn making their page rank higher, meaning that they do indeed indirectly increase page’s page ranks\n",
    "through their queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
